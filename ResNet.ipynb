{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        stride = out_channels // in_channels\n",
    "        self.non_linear_pipe = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        \n",
    "        if stride == 1:\n",
    "            self.shortcut_pipe = nn.Sequential()\n",
    "        else:\n",
    "            self.shortcut_pipe = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )          \n",
    "    \n",
    "    def forward(self, x):\n",
    "        Fx = self.non_linear_pipe(x)\n",
    "        y = Fx + self.shortcut_pipe(x)\n",
    "        Hx = F.relu(y)\n",
    "        return Hx\n",
    "\n",
    "class ResStack(nn.Module):\n",
    "    def __init__(self, n_layers, n_filters, in_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        in_channel_list = [in_channels] + (n_layers-1)*[n_filters]\n",
    "        for id_layer in range(0, n_layers):\n",
    "            layers.append(ResLayer(in_channel_list[id_layer], n_filters))\n",
    "        self.layers = nn.Sequential(*layers) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, n_filters_0=16, input_size=32, n_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.initial_pipe = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=n_filters_0, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(n_filters_0),\n",
    "        )\n",
    "        \n",
    "        stacks = []\n",
    "        for id_stack in range(0,3):\n",
    "            n_layers = 2\n",
    "            in_channels = n_filters_0*(2**max(0,id_stack-1))\n",
    "            n_filters = n_filters_0*(2**id_stack)\n",
    "            stacks.append(ResStack(n_layers, n_filters, in_channels))\n",
    "        self.stack = nn.Sequential(*stacks)\n",
    "        \n",
    "        self.avg_pool_layer = nn.AvgPool2d(input_size//(2**2))\n",
    "        self.linear_layers = nn.Linear(n_filters_0*(2**2), n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.initial_pipe(x)\n",
    "        y = self.stack(y)\n",
    "        y = self.avg_pool_layer(y)\n",
    "        y = self.linear_layers(y.view(y.size(0),-1))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet18().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_optimizer = optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   391] loss: 2.253\n",
      "[2,   391] loss: 2.127\n",
      "[3,   391] loss: 2.026\n",
      "[4,   391] loss: 1.950\n",
      "[5,   391] loss: 1.891\n",
      "[6,   391] loss: 1.840\n",
      "[7,   391] loss: 1.794\n",
      "[8,   391] loss: 1.753\n",
      "[9,   391] loss: 1.717\n",
      "[10,   391] loss: 1.687\n",
      "[11,   391] loss: 1.659\n",
      "[12,   391] loss: 1.634\n",
      "[13,   391] loss: 1.614\n",
      "[14,   391] loss: 1.591\n",
      "[15,   391] loss: 1.571\n",
      "[16,   391] loss: 1.552\n",
      "[17,   391] loss: 1.534\n",
      "[18,   391] loss: 1.514\n",
      "[19,   391] loss: 1.498\n",
      "[20,   391] loss: 1.480\n",
      "[21,   391] loss: 1.465\n",
      "[22,   391] loss: 1.448\n",
      "[23,   391] loss: 1.431\n",
      "[24,   391] loss: 1.415\n",
      "[25,   391] loss: 1.400\n",
      "[26,   391] loss: 1.385\n",
      "[27,   391] loss: 1.371\n",
      "[28,   391] loss: 1.357\n",
      "[29,   391] loss: 1.342\n",
      "[30,   391] loss: 1.326\n",
      "[31,   391] loss: 1.311\n",
      "[32,   391] loss: 1.297\n",
      "[33,   391] loss: 1.285\n",
      "[34,   391] loss: 1.270\n",
      "[35,   391] loss: 1.257\n",
      "[36,   391] loss: 1.243\n",
      "[37,   391] loss: 1.228\n",
      "[38,   391] loss: 1.216\n",
      "[39,   391] loss: 1.203\n",
      "[40,   391] loss: 1.191\n",
      "[41,   391] loss: 1.177\n",
      "[42,   391] loss: 1.166\n",
      "[43,   391] loss: 1.155\n",
      "[44,   391] loss: 1.142\n",
      "[45,   391] loss: 1.134\n",
      "[46,   391] loss: 1.122\n",
      "[47,   391] loss: 1.110\n",
      "[48,   391] loss: 1.103\n",
      "[49,   391] loss: 1.091\n",
      "[50,   391] loss: 1.080\n",
      "[51,   391] loss: 1.073\n",
      "[52,   391] loss: 1.064\n",
      "[53,   391] loss: 1.055\n",
      "[54,   391] loss: 1.045\n",
      "[55,   391] loss: 1.037\n",
      "[56,   391] loss: 1.031\n",
      "[57,   391] loss: 1.023\n",
      "[58,   391] loss: 1.016\n",
      "[59,   391] loss: 1.008\n",
      "[60,   391] loss: 1.000\n",
      "[61,   391] loss: 0.992\n",
      "[62,   391] loss: 0.984\n",
      "[63,   391] loss: 0.977\n",
      "[64,   391] loss: 0.970\n",
      "[65,   391] loss: 0.962\n",
      "[66,   391] loss: 0.956\n",
      "[67,   391] loss: 0.949\n",
      "[68,   391] loss: 0.943\n",
      "[69,   391] loss: 0.937\n",
      "[70,   391] loss: 0.932\n",
      "[71,   391] loss: 0.923\n",
      "[72,   391] loss: 0.917\n",
      "[73,   391] loss: 0.915\n",
      "[74,   391] loss: 0.908\n",
      "[75,   391] loss: 0.903\n",
      "[76,   391] loss: 0.896\n",
      "[77,   391] loss: 0.892\n",
      "[78,   391] loss: 0.884\n",
      "[79,   391] loss: 0.878\n",
      "[80,   391] loss: 0.874\n",
      "[81,   391] loss: 0.869\n",
      "[82,   391] loss: 0.866\n",
      "[83,   391] loss: 0.858\n",
      "[84,   391] loss: 0.853\n",
      "[85,   391] loss: 0.848\n",
      "[86,   391] loss: 0.845\n",
      "[87,   391] loss: 0.838\n",
      "[88,   391] loss: 0.833\n",
      "[89,   391] loss: 0.828\n",
      "[90,   391] loss: 0.824\n",
      "[91,   391] loss: 0.818\n",
      "[92,   391] loss: 0.816\n",
      "[93,   391] loss: 0.808\n",
      "[94,   391] loss: 0.804\n",
      "[95,   391] loss: 0.799\n",
      "[96,   391] loss: 0.794\n",
      "[97,   391] loss: 0.791\n",
      "[98,   391] loss: 0.788\n",
      "[99,   391] loss: 0.781\n",
      "[100,   391] loss: 0.776\n",
      "[101,   391] loss: 0.776\n",
      "[102,   391] loss: 0.769\n",
      "[103,   391] loss: 0.764\n",
      "[104,   391] loss: 0.763\n",
      "[105,   391] loss: 0.755\n",
      "[106,   391] loss: 0.752\n",
      "[107,   391] loss: 0.746\n",
      "[108,   391] loss: 0.748\n",
      "[109,   391] loss: 0.741\n",
      "[110,   391] loss: 0.736\n",
      "[111,   391] loss: 0.730\n",
      "[112,   391] loss: 0.728\n",
      "[113,   391] loss: 0.721\n",
      "[114,   391] loss: 0.718\n",
      "[115,   391] loss: 0.715\n",
      "[116,   391] loss: 0.710\n",
      "[117,   391] loss: 0.707\n",
      "[118,   391] loss: 0.703\n",
      "[119,   391] loss: 0.698\n",
      "[120,   391] loss: 0.693\n",
      "[121,   391] loss: 0.690\n",
      "[122,   391] loss: 0.683\n",
      "[123,   391] loss: 0.682\n",
      "[124,   391] loss: 0.679\n",
      "[125,   391] loss: 0.675\n",
      "[126,   391] loss: 0.669\n",
      "[127,   391] loss: 0.665\n",
      "[128,   391] loss: 0.660\n",
      "[129,   391] loss: 0.655\n",
      "[130,   391] loss: 0.655\n",
      "[131,   391] loss: 0.649\n",
      "[132,   391] loss: 0.644\n",
      "[133,   391] loss: 0.643\n",
      "[134,   391] loss: 0.640\n",
      "[135,   391] loss: 0.637\n",
      "[136,   391] loss: 0.632\n",
      "[137,   391] loss: 0.627\n",
      "[138,   391] loss: 0.625\n",
      "[139,   391] loss: 0.619\n",
      "[140,   391] loss: 0.616\n",
      "[141,   391] loss: 0.612\n",
      "[142,   391] loss: 0.607\n",
      "[143,   391] loss: 0.604\n",
      "[144,   391] loss: 0.601\n",
      "[145,   391] loss: 0.597\n",
      "[146,   391] loss: 0.594\n",
      "[147,   391] loss: 0.589\n",
      "[148,   391] loss: 0.585\n",
      "[149,   391] loss: 0.583\n",
      "[150,   391] loss: 0.577\n",
      "[151,   391] loss: 0.573\n",
      "[152,   391] loss: 0.575\n",
      "[153,   391] loss: 0.565\n",
      "[154,   391] loss: 0.565\n",
      "[155,   391] loss: 0.561\n",
      "[156,   391] loss: 0.556\n",
      "[157,   391] loss: 0.552\n",
      "[158,   391] loss: 0.549\n",
      "[159,   391] loss: 0.545\n",
      "[160,   391] loss: 0.539\n",
      "[161,   391] loss: 0.539\n",
      "[162,   391] loss: 0.537\n",
      "[163,   391] loss: 0.532\n",
      "[164,   391] loss: 0.530\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(164):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        res_optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        res_optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += (loss.item() - running_loss)/(i+1)\n",
    "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss), end=\"\\r\")\n",
    "            \n",
    "    print('')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_shallowRN = './cifar_resnet_shallow.pth'\n",
    "torch.save(resnet.state_dict(), PATH_shallowRN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_RN = 0\n",
    "total_RN = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = resnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_RN += labels.size(0)\n",
    "        correct_RN += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of ResNet18 on the 10000 test images: %d %%' % (\n",
    "    100 * correct_RN / total_RN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
